{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from fa2 import ForceAtlas2\n",
    "import numpy as np\n",
    "import csv\n",
    "import networkx as nx\n",
    "import os\n",
    "#couchsurfing API is external API locally saved also available in our github: https://github.com/eikekutz/SocialGraphFinalProject\n",
    "from couchsurfing import Api\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from geopy import geocoders\n",
    "import unidecode\n",
    "import conda\n",
    "#Necessary Settings for the conda package to work with the Basemap\n",
    "conda_file_dir = conda.__file__\n",
    "conda_dir = conda_file_dir.split('lib')[0]\n",
    "proj_lib = os.path.join(os.path.join(conda_dir, 'share'), 'proj')\n",
    "os.environ[\"PROJ_LIB\"] = proj_lib\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **0\\. Data Extraction**\n",
    "    * 0.1\\. Couchsurfing API Data Gathering\n",
    "        * 0.1.1\\. Get Hosts Data\n",
    "        * 0.1.2\\. Get Reviews and Reviewers Data\n",
    "    * 0.2\\. Data Merging\n",
    "    * 0.3\\. Adding Geo Location of Users\n",
    "    * 0.4\\. Cleaning Data\n",
    "    \n",
    "* 1\\. Project's objective (**fix list problem**)\n",
    "    * 1.1\\. What do we want to answer in this project\n",
    "    * 1.2\\. Datasets limitations\n",
    "    \n",
    "* **2\\. Preliminary Data Analysis**\n",
    "    * 2.1\\. User\n",
    "        * 2.1.1\\. User Analysis\n",
    "        * 2.1.2\\. User Statistics\n",
    "        * 2.1.3\\. User Graphs\n",
    "    * 2.2\\. City\n",
    "        * 2.2.1\\. City Clustering\n",
    "        * 2.2.2\\. City Analysis\n",
    "        * 2.2.3\\. City Statistics\n",
    "        * 2.2.4\\. City Graphs\n",
    "\n",
    "* **3\\. Network Construction**\n",
    "    * 3.1\\.User \n",
    "        * 3.1.1\\. Initial Analysis\n",
    "        * 3.1.2\\. Alternative Construction\n",
    "    * 3.2\\.City \n",
    "        * 3.2.1\\. Initial Analysis\n",
    "        * 3.2.2\\. Alternative Construction\n",
    "\n",
    "* **4\\. Basic Network Analysis**\n",
    "    * 4.1\\. Degree Distribution\n",
    "    * 4.2\\. Power-laws and Friendship Paradox\n",
    "    * 4.3\\. Centrality\n",
    "    * 4.4\\. Assortativity\n",
    "    * 4.5\\. Modularity and Communities\n",
    "    * 4.6\\. Network Visualizations and Statistics\n",
    "\n",
    "* **5\\. Analysis of Review data**\n",
    "    * 5.1\\. Wordclouds\n",
    "    * 5.2\\. Happiness Averages\n",
    "        * 5.2.1\\. Users\n",
    "        * 5.2.2\\. Cities\n",
    "\n",
    "* **6\\. Analysis of specific Users**\n",
    "    * 6.1\\. Combined sentiment\n",
    "        * 6.1.1\\.  Image Sentiment\n",
    "        * 6.1.1\\.  Profile description Sentiment\n",
    "    * 6.2\\. Best/Worst User\n",
    "        * 6.2.1\\. Best/Worst Couchsurfer\n",
    "        * 6.2.1\\. Best Host\n",
    "\n",
    "* **7\\. Discussion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.Data Extraction#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHostFromCity(city,latitude,longitude):\n",
    "    '''\n",
    "    getting all the host data within a circle with a radius of 25km \n",
    "    max 20 pages with each 100 users\n",
    "    '''\n",
    "    print(\"Getting results for \",city,latitude,longitude)\n",
    "    for p in range(1,20):\n",
    "        print(p)\n",
    "        ##hosts = api.get_hosts(city,25,100,p)\n",
    "        ##hosts = api.get_hosts(city,25,100,None,'best_match',\"yes,maybe\",None,p,last_login)\n",
    "        hosts = api.get_hosts_latlong(latitude,longitude,p,100,25,4)\n",
    "        writeCityResults2File(hosts,city,p)\n",
    "        sleep(randint(2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeCityResults2File(results,cityString,page):\n",
    "    '''\n",
    "    writing hosts to csv file 100 users for each file\n",
    "    '''\n",
    "    with open('data/Top50/hosts/'+cityString+str(page)+'.csv','w',newline=\"\") as f:\n",
    "        writer = csv.writer(f,delimiter = ',')\n",
    "        # Write CSV Header, If you dont need that, remove this line\n",
    "        writer.writerow([\"id\",\n",
    "                \"publicName\",\n",
    "                \"avatarUrl\",\n",
    "                \"isVerified\",\n",
    "                \"status\",\n",
    "                \"lastLogin\",\n",
    "                \"aboutText\",\n",
    "                \"responseRate\",\n",
    "                \"responseTimeText\",\n",
    "                'responseRateText',\n",
    "                \"totalReferencesCount\",\n",
    "                \"profileLink\",\n",
    "                \"friendsCount\",\n",
    "                \"languages\",\n",
    "                \"city\"])\n",
    "\n",
    "        for host in results['results']:\n",
    "            writer.writerow([host[\"id\"],\n",
    "                    host[\"publicName\"],\n",
    "                    host[\"avatarUrl\"],\n",
    "                    host[\"isVerified\"],\n",
    "                    host[\"status\"],\n",
    "                    host[\"lastLogin\"],\n",
    "                    host[\"aboutText\"],\n",
    "                    host[\"responseRate\"],\n",
    "                    host[\"responseTimeText\"],\n",
    "                    host[\"responseRateText\"],\n",
    "                    host[\"totalReferencesCount\"],\n",
    "                    host[\"profileLink\"],\n",
    "                    host[\"friendsCount\"],\n",
    "                    host[\"languages\"],\n",
    "                    cityString])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nodes to get id from nodes/hosts\n",
    "def importHosts(index):\n",
    "    '''\n",
    "    Import merged hosts to get id, which is used to download the reviews for each user\n",
    "    '''\n",
    "    hosts = pd.DataFrame() #creates a new dataframe that's empty\n",
    "    city = cities.loc[index]\n",
    "    for p in range(1,15):\n",
    "        if (os.path.exists('data/Top50/hosts/'+city['name']+str(p)+'.csv')):\n",
    "            df = pd.read_csv('data/Top50/hosts/'+city['name']+str(p)+'.csv')\n",
    "            hosts = pd.concat([hosts,df]).reset_index(drop=True)\n",
    "    return hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRevCityList(city): \n",
    "    '''\n",
    "    Create a csv file for the given city to store reviews of the city\n",
    "    '''\n",
    "    with open('data/Top50/reviews/'+city+'Rev.csv','w',newline=\"\") as f:\n",
    "            writer = csv.writer(f,delimiter = ',')\n",
    "            writer.writerow([\"id\",\n",
    "                    \"text\",\n",
    "                    \"createdDate\",\n",
    "                    \"experience\",\n",
    "                    \"relationshipType\",\n",
    "                    \"isPostTrip\",\n",
    "                    \"to\",\n",
    "                    \"from\",\n",
    "                    \"fromPublicName\",\n",
    "                    \"fromPublicAddressId\",\n",
    "                    \"fromPublicAddressDescription\",\n",
    "                    \"fromAvatarUrl\",\n",
    "                    \"fromStatus\",\n",
    "                    \"fromIsVerified\",\n",
    "                    \"fromIsDeleted\",\n",
    "                    \"fromBlockedBy\",\n",
    "                    \"inverseReference\",\n",
    "                    \"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendReview(file,city):\n",
    "    '''\n",
    "    Append Reviews of the user on the specific city reviews csv file\n",
    "    '''\n",
    "    with open('data/Top50/reviews/'+city+'Rev.csv','a',newline=\"\") as f:\n",
    "        writer = csv.writer(f,delimiter = ',')\n",
    "        for host in file['results']:\n",
    "            writer.writerow([host[\"id\"],\n",
    "                host[\"text\"],\n",
    "                host[\"createdDate\"],\n",
    "                host[\"experience\"],\n",
    "                host[\"relationshipType\"],\n",
    "                host[\"isPostTrip\"],\n",
    "                host[\"to\"]['id'],\n",
    "                host[\"from\"]['id'],\n",
    "                host[\"from\"][\"publicName\"],\n",
    "                host[\"from\"][\"publicAddress\"][\"id\"],\n",
    "                host[\"from\"][\"publicAddress\"][\"description\"],\n",
    "                host[\"from\"][\"avatarUrl\"],\n",
    "                host[\"from\"][\"status\"],\n",
    "                host[\"from\"][\"isVerified\"],\n",
    "                host[\"from\"][\"isDeleted\"],\n",
    "                host[\"from\"][\"blockedBy\"],\n",
    "                host[\"inverseReference\"],\n",
    "                host[\"response\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReferenceForCity(index):\n",
    "    '''\n",
    "    Get the reviews for every hosts for a given city based on the downloaded host dataset\n",
    "    '''\n",
    "    hosts= importHosts(index=index)\n",
    "    city = cities.loc[index]\n",
    "    print(\"Getting results for \",city['name'])\n",
    "    createRevCityList(city['name'])\n",
    "    for idx,host in hosts.iterrows():\n",
    "        test=api.get_references(uid=host['id'],type='host')\n",
    "        appendReview(test,city['name'])\n",
    "        test=api.get_references(uid=host['id'],type='surf')\n",
    "        appendReview(test,city['name'])     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Couchsurfing API Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the hosts from a city , iterating over the city list\n",
    "for idx,city in cities.iterrows():#.loc[cities['2017']>50000].iterrows():\n",
    "    getHostFromCity(city['name'],city['lat'],city['lng'])\n",
    "    sleep(randint(10,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the references for all the hosts\n",
    "for idx,city in cities.iterrows():#.loc[cities['2017']>50000].iterrows():\n",
    "    if idx>10:\n",
    "        getReferenceForCity(idx)\n",
    "        sleep(randint(5,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Data Merging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging host's data\n",
    "hosts = pd.DataFrame() #creates a new dataframe that's empty\n",
    "for idx,city in cities.iterrows():#.loc[cities['2017']>50000].iterrows():\n",
    "    for p in range(1,14):\n",
    "        if (os.path.exists('data/Top50/hosts/'+city['name']+str(p)+'.csv')):\n",
    "            df = pd.read_csv('data/Top50/hosts/'+city['name']+str(p)+'.csv',index_col=False,dtype={'id': np.int64})\n",
    "            hosts = pd.concat([hosts,df]).reset_index(drop=True)\n",
    "hosts=hosts.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging review data\n",
    "rev = pd.DataFrame() #creates a new dataframe that's empty\n",
    "for idx,city in cities.iterrows():#.loc[cities['2017']>50000].iterrows():\n",
    "    if os.path.exists('data/Top50/reviews/'+city['name']+'Rev.csv'):\n",
    "        df = pd.read_csv('data/Top50/reviews/'+city['name']+'Rev.csv',index_col=False)\n",
    "        rev = pd.concat([rev,df]).reset_index(drop=True)\n",
    "rev=rev.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3. Adding Geo Location of Users\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_not_found = []\n",
    "def getCityCoords(name):\n",
    "    gn = geocoders.GeoNames(username='kacper')\n",
    "    try:\n",
    "        loc = gn.geocode(name, timeout=10)\n",
    "        if loc is None:\n",
    "            try: \n",
    "                loc =gn.geocode(name.split(',')[0],timeout=10)\n",
    "                if loc is None:\n",
    "                    raise TypeError\n",
    "            except Exception as inst:\n",
    "                print('This city was not found:',name)\n",
    "                return None\n",
    "    except Exception as inst:\n",
    "        print('This city was not found:',name)\n",
    "        cities_not_found.append(name)\n",
    "        return None\n",
    "    #print(len(loc))\n",
    "   # print(loc[0].raw)\n",
    "    return loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://www.maxmind.com/en/free-world-cities-database\n",
    "worldCities = pd.read_csv('../worldcitiespop.txt',encoding = \"ISO-8859-1\")\n",
    "#source: https://datahub.io/core/country-list#resource-data\n",
    "cc= pd.read_csv('data/country_map.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries worldCitiespop.txt:  3173958\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>AccentCity</th>\n",
       "      <th>Region</th>\n",
       "      <th>Population</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad</td>\n",
       "      <td>aixas</td>\n",
       "      <td>Aixàs</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.483333</td>\n",
       "      <td>1.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ad</td>\n",
       "      <td>aixirivali</td>\n",
       "      <td>Aixirivali</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.466667</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ad</td>\n",
       "      <td>aixirivall</td>\n",
       "      <td>Aixirivall</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.466667</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country        City  AccentCity Region  Population   Latitude  Longitude\n",
       "0      ad       aixas       Aixàs      6         NaN  42.483333   1.466667\n",
       "1      ad  aixirivali  Aixirivali      6         NaN  42.466667   1.500000\n",
       "2      ad  aixirivall  Aixirivall      6         NaN  42.466667   1.500000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example how the data look like:\n",
    "print('Number of entries worldCitiespop.txt: ',len(worldCities))\n",
    "worldCities.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uniqueCities=rev.fromPublicAddressDescription.unique()\n",
    "uniqueCities = uniqueCities.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Part we map a geographical position to every review.\n",
    "With this information we know the reviewer geographical position.\n",
    "Due to the high number of reviewer's unique locations and the geopy API's limitation of 5000 requests a day we used the worldcitiespop.txt.\n",
    "If an entry couldn't be found in this list we used the geopy API to supplement the missing entries.\n",
    "If a review's location couldn't be found it will be droppend afterwards.\n",
    "The nummber of not found location is 815 out of 96085 with is a 0.848% of the reviews data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exList=[\"nan\"]\n",
    "for city in unique:\n",
    "    if all([c[1]=='NaN'for c in rev.loc[rev.fromPublicAddressDescription==city]['lat'].iteritems()]):\n",
    "        if str(city).lower() not in exList:\n",
    "            #Search for entry in the worldcities list and map with country code (cc) if necessary\n",
    "            loc = worldCities.loc[worldCities.City==city.split(',')[0].lower().strip()]\n",
    "            if len(loc.index)>1:\n",
    "                try:\n",
    "                    countryCode = cc.loc[cc.Name==city.split(',')[-1].strip().lower().title()]['Code'].values[0]\n",
    "                    loc =loc.loc[loc.Country==countryCode.lower()].head(1)\n",
    "                except:\n",
    "                    loc=loc.head(1)\n",
    "            if len(loc.head(1).index)==0:\n",
    "                c=test=unidecode.unidecode(city)\n",
    "                loc = worldCities.loc[worldCities.City==c.split(',')[0].lower().strip()].head(1)\n",
    "                if len(loc.index)>1:\n",
    "                    try:\n",
    "                        countryCode = cc.loc[cc.Name==c.split(',')[-1].strip().lower().title()]['Code'].values[0]\n",
    "                        loc =loc.loc[loc.Country==countryCode.lower()].head(1)\n",
    "                    except:\n",
    "                        loc=loc.head(1)  \n",
    "\n",
    "            if len(loc.head(1).index)==1:\n",
    "                l=rev.loc[rev.fromPublicAddressDescription==city].index.tolist()\n",
    "                for i in l:\n",
    "                    rev.set_value(i,'lat',loc.Latitude.values[0])\n",
    "                    rev.set_value(i,'lng',loc.Longitude.values[0])\n",
    "                    rev.set_value(i,'city',loc.City.values[0])\n",
    "                    rev.set_value(i,'country',loc.Country.values[0])\n",
    "\n",
    "            else:\n",
    "            #is the entry not found in the worldcities use the API to download the geoposition    \n",
    "                print('try api for :',city)\n",
    "                res = getCityCoords(city)\n",
    "                try:\n",
    "                    l=rev.loc[rev.fromPublicAddressDescription==city].index.tolist()\n",
    "                    for i in l:\n",
    "                        rev.set_value(i,'lat',res.latitude)\n",
    "                        rev.set_value(i,'lng',res.longitude)\n",
    "                        rev.set_value(i,'city',res.address.split(' ')[0].lower())\n",
    "                        rev.set_value(i,'country',res.address.split(' ')[-1].lower())\n",
    "                except:\n",
    "                    print('Could not found ',city)\n",
    "export_csv = rev.to_csv ('data/reviews_total_geo_x.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4. Cleaning Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
